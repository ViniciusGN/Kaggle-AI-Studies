{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8 - Diffusion Models (DM) \n",
    "## Denoising Diffusion Probabilistic Models (DDPM) and Denoising Diffusion Implicit Models (DDIM)\n",
    "\n",
    "This class of methods is based stochastic processes that iteratively refine a noisy sample to generate new data points. They are particularly effective for generating high-quality samples (images, text, audio ...) and have become a popular choice in generative modeling.\n",
    "\n",
    "\n",
    "### Principles and key concepts\n",
    "\n",
    "The key idea is to start with a simple noise distribution (latent) and **iteratively** denoise it to produce samples that resemble the training data.\n",
    "Similarily to Normalizing Flows (NFs), diffusion models learn a transformation from a simple distribution (often Gaussian noise) to the data distribution, but they do so through a stochastic process (*Stochastic Differential Equation* or SDE) rather than a single deterministic mapping (neural decoder).\n",
    "As a consequence, the latent representation of the data again lives in the same space as the data itself (like NFs), which is a key difference with GANs or VAEs that learn a latent space that is typically lower-dimensional than the data space.\n",
    "\n",
    "The forward process (noising) is usually a Markov chain that gradually adds noise to the data which can be efficiently achieved, while the reverse process (denoising) is learned using a neural network that predicts the noise at each step.\n",
    "\n",
    "### Modeling\n",
    "The diffusion process is discretized as a time sequence where $t \\in \\llbracket 0,T \\rrbracket$ typically divided into two main phases: \n",
    "\n",
    "- a stochastic forward diffusion process (from $t=0$ to $t=T$) that adds noise to a clean data point $x_0$ to produce a noisy sample $x_T$:\n",
    "$$\n",
    "    x_{t+1} = f_\\theta(x_t, t) + \\epsilon_t\n",
    "$$\n",
    "where $f_\\theta$ is a (simple) parametric function of the current point $x_t$ that is linearly combined with the noise $\\epsilon_t$ to be added at each step. Typically $\\epsilon_t \\sim \\mathcal N(\\mu_t, \\Sigma_t)$ is a noise term sampled from a Gaussian distribution, such that the noise level increases with $t$. By the end of the process ($t=T$), the data is almost entirely noise, and $x_T$ is close to a Gaussian distribution that is easy to sample from.\n",
    "\n",
    "- a reverse diffusion process (from $t=T$ to $t=0$) that denoises the noisy random samples $x_T$ to generate new data points:\n",
    "$$    x_{t-1} = g_\\theta(x_t, t) + \\epsilon_t$$\n",
    "where $g_\\theta$ is a complex parametric function (a neural network) that learns to reverse the noise addition process\n",
    "and $\\epsilon_t$ is again typically a noise term sampled from a Gaussian distribution.\n",
    "\n",
    "\n",
    "The training objective is to minimize the difference between the predicted noise and the actual noise added during the forward process, often using a mean squared error loss.\n",
    "\n",
    "Once trained, the model can generate new samples by starting with a random noise vector and iteratively applying the learned reverse diffusion process to denoise it.\n",
    "\n",
    "This approach has shown impressive results in generating high-quality images and has been widely adopted in various applications, including image synthesis, inpainting, and super-resolution.\n",
    "\n",
    "\n",
    "### Architecture\n",
    "\n",
    "Contrary to other generative models studied previously (GANs, NFs, VAEs) that are based on specific architectures (encoders, decoders, etc.), the architecture of diffusion models is solely based on a neural network that learns to transform a simple noise distribution into the data distribution.\n",
    "This neural network $g_\\theta$ can be any architecture that is suitable for the task (here a simple MLP), such as convolutional networks for image data (typically a U-Net) or recurrent networks for sequential data.\n",
    "The only key requirements is that \n",
    "\n",
    "1. the input $x_t$ and output $y_t$ of the neural network $y_t = g_\\theta(x_t, t)$ are of the same dimension as the data, and\n",
    "\n",
    "2. the neural network $g_\\theta(x_t, t)$ depends on the time step $t$ to allow the model to learn different transformations at each step of the diffusion process.\n",
    "\n",
    "As the number of time steps is typically large (e.g. $T=1,000$), rather than learning a different neural network for each time step $t$, this last requirement is typically achieved by concatenating the time step $t$ to the input of the neural network, or by using a positional encoding of the time step (e.g., sinusoidal encoding) to inject the time information into the model.\n",
    "\n",
    "---\n",
    "\n",
    "References:\n",
    "- Diffusion model : \"Deep Unsupervised Learning using Nonequilibrium Thermodynamics\", Sohl-Dickstein et al. (ICML, 2015)\n",
    "- DDPM: \"Denoising Diffusion Probabilistic Models\" by Ho et al. (NeuRIPS 2020)\n",
    "- DDIM: \"Denoising Diffusion Implicit Models\" by Song et al. (ICLR 2021)\n",
    "\n",
    "julien rabin @ greyc.ensicaen.fr 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Course Recap on DDPM (Denoising Diffusion Probabilistic Models)\n",
    "\n",
    "\n",
    "### Forward diffusion process with DDPM\n",
    "\n",
    "The Forward diffusion process is defined in DDPM as the iterative \"variance-preserving\" stochastic process:\n",
    "$$\n",
    "    x_t = \\sqrt{1 - \\beta_t} x_{t-1} + \\sqrt{\\beta_t} \\epsilon\n",
    "    \\quad \\text{ where } \\epsilon \\sim \\mathcal N(0, I_d)\n",
    "$$\n",
    "where $\\beta_t$ is a small positive constant that controls the amount of noise added at each step:\n",
    "$$\\boxed{\\color{orange}\\text{noise\\ schedule}: \\quad\n",
    "    \\beta_t =  \\tfrac{t}{T}\\beta_T + (1-\\tfrac{t}{T}) \\beta_0\n",
    "    \\quad \\text{ with } T=1000, \\beta_0 = 0.0001,  \\beta_T = 0.02\n",
    "}\n",
    "$$\n",
    "Note $I_d$ is the identity matrix for $d$-dimensional data $x_t \\in \\mathbb R^d$.\n",
    "This means that the forward process is a fixed Markov chain that adds noise to the data:\n",
    "$$\n",
    "    q(x_t | x_{t-1}) = \\mathcal N(x_t; \\sqrt{1 - \\beta_t} x_{t-1}, \\beta_t I_d)\n",
    "$$\n",
    "\n",
    "Rather than iterating this stochastic process, a more efficient (and equivalent) way to define the forward diffusion process is to use a closed-form expression that directly computes the noisy sample $x_t$ from the original data point $x_0$:\n",
    "$$    \n",
    "    q(x_t | x_0) = \\mathcal N(x_t; \\sqrt{\\bar \\alpha_t} x_0, (1 - \\bar \\alpha_t) I_d)\n",
    "$$\n",
    "where $\\alpha_t  = 1 - \\beta_t$  and $\\bar \\alpha_t = \\prod_{s=1}^{t} \\alpha_s$ is the cumulative product of the noise coefficients up to time $t$.\n",
    "\n",
    "$$\\color{blue}\n",
    "\\boxed{\\text{forward\\ diffusion\\ process}: \\quad\n",
    "    x_t = \\sqrt{\\bar \\alpha_t} x_0 + \\sqrt{1 - \\bar \\alpha_t} \\epsilon\n",
    "    \\quad \\text{ where } \\epsilon \\sim \\mathcal N(0, I_d)\n",
    "}\n",
    "$$\n",
    "\n",
    "### Reverse diffusion process with DDPM\n",
    "\n",
    "The reverse diffusion process is learned by a neural network $g_\\theta$.\n",
    "In DDPM, a reparamtrization is used to directly train a denoising network $\\varepsilon_\\theta(x_t, t)$ that predicts the noise $\\epsilon$ added at each step of the forward process.\n",
    "The reverse process is defined as:\n",
    "$$    p_\\theta(x_{t-1} | x_t) = \\mathcal N(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t))$$\n",
    "where the mean $\\mu_\\theta(x_t, t)$ and covariance $\\Sigma_\\theta(x_t, t)$ are predicted by the neural network $\\varepsilon_\\theta(x_t, t)$.\n",
    "The mean is typically defined as:\n",
    "$$    \\mu_\\theta(x_t, t) = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar \\alpha_t}} \\varepsilon_\\theta(x_t, t) \\right)$$\n",
    "and the covariance is usually set to a fixed value, such as $\\Sigma_\\theta(x_t, t) = \\sigma_t^2 I_d$ where $\\sigma_t^2$ is a small constant (in DDPM $\\sigma_t^2 = \\beta_t$, but other choices are possible).\n",
    "\n",
    "\n",
    "$$\\color{magenta}\n",
    "\\boxed{\\text{backward\\ diffusion\\ process}: \\quad\n",
    "    x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{\\beta_t}{\\sqrt{1 - \\bar \\alpha_t}} \\varepsilon_\\theta(x_t, t) \\right) + \\sqrt{\\beta_t} \\epsilon\n",
    "    \\quad \\text{ where } \\epsilon \\sim \\mathcal N(0, I_d)\n",
    "}\n",
    "$$\n",
    "\n",
    "### Training\n",
    "\n",
    "The training of diffusion models such as DDPM is typically done by maximizing the likelihood of the data under the learned distribution:\n",
    "$$\n",
    "    \\mathcal L(\\theta) = \\mathbb E_{x_0 \\sim p_{data}} \\left[ \\log p_\\theta(x_0) \\right]\n",
    "$$\n",
    "where $p_\\theta$ is the density of data points $x_0$ under the learned distribution which is obtained by iterating the diffusion process $x_T,x_{T-1}, ..., x_1, x_0$:\n",
    "$$\n",
    "    p_\\theta(x_0) \n",
    "    = \\int_{x_1, \\ldots, x_T} p_\\theta(x_0, x_1, \\ldots, x_T) dx_1 \\cdots dx_T\n",
    "    %= \\int_{x_1, \\ldots, x_T} p_\\theta(x_0|x_1) p_\\theta(x_1|x_2) \\cdots p_\\theta(x_{T-1}|x_T) p(x_T) dx_1 \\cdots dx_T\n",
    "$$\n",
    "where $p_\\theta(x_0, x_1, \\ldots, x_T)$ is the joint distribution of the data and the latent variables at each time step which can be factorized as:\n",
    "$$    p_\\theta(x_0, x_1, \\ldots, x_T) = p(x_T) \\prod_{t=1}^{T} p_\\theta(x_{t-1} | x_t)$$\n",
    "where $p(x_T)$ is the prior distribution of the latent variable $x_T$, that converges (large $T$) to a standard Gaussian distribution $\\mathcal N(0,I_d)$.\n",
    "\n",
    "As for VAEs, this likelihood is intractable to compute directly.\n",
    "However, as demonstrated in DDPM (see details in course), it is possible to train the model by minimizing a reparametrized loss function that approximates the likelihood of the data (lower bound as in VAEs):\n",
    "$$\\boxed{\\color{green}\n",
    "    \\min_\\theta \\mathbb{E}_{x_0, \\varepsilon, t} \\; \\| \\varepsilon - \\varepsilon_\\theta (x_t, t)  \\|^2\n",
    "}\n",
    "$$\n",
    "where $x_t$ is sampled from the forward diffusion process $q(x_t | x_0)$, that is using a random standard noise $\\varepsilon$ added to $x_0$ to obtain $x_t$. Time step $t$ is a discrete random variable sampled uniformly from $\\llbracket 0,T \\rrbracket$.\n",
    "\n",
    "### Inference with Denoising Diffusion Implicit Models (DDIM)\n",
    "\n",
    "Once the model is trained, it can be used to generate new samples by starting from a random noise vector $x_T$ and iteratively applying the learned reverse diffusion process.\n",
    "\n",
    "In DDIM, this reverse diffusion process is modified to allow for a more efficient sampling process that does not require the full Markov chain of steps.\n",
    "\n",
    "Instead of sampling from the learned distribution at each step, DDIM uses a deterministic mapping by replacing the stochastic noise term with a **fixed noise term computed from the learned model**:\n",
    "$$\\boxed{\\text{DDIM\\ backward\\ diffusion\\ process}: \\quad\n",
    "\\begin{aligned}\n",
    "    x_{t-1} = \\sqrt{\\bar \\alpha_{t-1}} {\\color{red} \\hat x_0} + \\sqrt{1 - \\bar \\alpha_{t-1}}\n",
    "\\varepsilon_\\theta (x_t,t)\n",
    "\\\\\n",
    "\\text{ where }\n",
    "    {\\color{red} \\hat x_0 = \\tfrac{1}{\\sqrt{\\bar \\alpha_t}}\n",
    "\\left(  x_{t} - \\sqrt{1 - \\bar \\alpha_t} \\varepsilon_\\theta (x_t,t) \\right) }\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "### Implementation\n",
    "We implement here in pytorch the a simple denoising model based on a MLP that is conditioned on the time step $t$ by concatenating it to the input $x_t$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries import and useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn, Tensor\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(n: int, model = 'moons') -> Tensor:\n",
    "    data_dim = 2  # Dimension of the data\n",
    "    if model == 'moons':\n",
    "        from sklearn.datasets import make_moons\n",
    "        return Tensor(make_moons(n_samples=n, noise=0.05)[0])\n",
    "    elif model == 'circles':\n",
    "        from sklearn.datasets import make_circles\n",
    "        return Tensor(make_circles(n_samples=n, noise=0.05, factor=0.5)[0])\n",
    "    elif model == '2gmm':\n",
    "        n_samples = n\n",
    "        n = n//3\n",
    "        X1 = torch.randn(n, data_dim) @ torch.tensor([[.05, -0.02],[-0.02, .4]]) + torch.tensor([[.0, 1.0]]).view(1, data_dim)\n",
    "        X2 = torch.randn(n_samples - n, data_dim) @ torch.tensor([[.3, 0.05],[0.05, .05]]) + torch.tensor([[-1.0, 0.]]).view(1, data_dim)\n",
    "        return torch.cat((X1,X2), dim=0)  # Concatenate the two sets of samples\n",
    "    elif model == 'radial_gmm':\n",
    "        K = 8\n",
    "        n_samples = n\n",
    "        samples_per_component = n_samples // K\n",
    "        remainder = n_samples % K\n",
    "        all_samples = []\n",
    "\n",
    "        for k in range(K):\n",
    "            radius = 3.\n",
    "            # Angle for the mean on a circle\n",
    "            theta = 2 * np.pi * k / K\n",
    "            cs = np.cos(theta)\n",
    "            sn = np.sin(theta)\n",
    "\n",
    "            # Radial direction unit vector\n",
    "            radial = torch.tensor([cs, sn], dtype=float)#.view(data_dim, 1)\n",
    "            tangential = torch.tensor([-sn, cs], dtype=float)#.view(data_dim, 1)\n",
    "\n",
    "            mean = radius * radial\n",
    "            \n",
    "            # Covariance matrix: elongated along radial direction\n",
    "            cov = 0.3 * torch.outer(radial, radial).to(float) + 0.05 * torch.outer(tangential, tangential).to(float)\n",
    "\n",
    "            # Generate samples\n",
    "            n = samples_per_component + (remainder if k == K else 0)\n",
    "            samples = torch.randn(n, data_dim, dtype=float) @ torch.linalg.cholesky(cov).to(float) + mean.to(float)\n",
    "            all_samples.append(samples)\n",
    "\n",
    "        return torch.cat(all_samples, dim=0).to(torch.float32)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 1 : Implementing diffusion forward encoder and DDPM/DDIM reverse processes\n",
    "\n",
    "Complete the following implementation of the `DDPM` class.\n",
    "Recall that \n",
    "- the latent encoder in AE/VAE (or the discriminator in GAN) is replaced here by a forward diffusion process: here the `noising` method (described by the equation in the blue box above) is parametrized by the noise schedule $\\beta_t$ (`self.beta`) (see above the boxed orange equation).\n",
    "- the reverse diffusion process iterative `denoising` (see equations in magenta for DDPM and red boxes for DDIM) is using a neural network (here `self.net`) in the `forward` method to predict the noise added at each step.\n",
    "- the neural network (here `self.net`) takes as input the noisy sample $x_t$ concatenated with a positional encoding of the time step $t$ to allow the model to learn different transformations at each step. This means that the input to the neural network is of dimension `data_dim + time_dim` where `time_dim` is the dimension of the positional encoding of the time step $t$ (here `data_dim=2` and `time_dim=1`) and the output is of dimension `data_dim=2`.\n",
    "- (see exercise 3 at the end) during inference, the `DDIM_denoising` method can be used instead of the `denoising` method with larger time steps to increase sampling speed while preserving the sampling quality ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDPM(nn.Module):\n",
    "    def __init__(self, dim: int = 2, h: int = 64, T : int = 1_000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(???, ???),\n",
    "        )\n",
    "        \n",
    "        self.T = T  # number of diffusion steps, t=0 is the initial clean position, t=T is the final gaussian position\n",
    "        self.t = torch.linspace(1, T, T)  # diffusion steps\n",
    "        beta0 = ...  # initial noise variance\n",
    "        betaT = ...\n",
    "        self.beta = beta0 + (betaT-beta0) * self.t/self.T  # linear schedule for the variance of the noise, i.e. x_t = \\sqrt{1-\\beta_t} x_0 + \\sqrt{\\beta_t} \\varepsilon\n",
    "        self.alpha = ... # alpha_t = 1 - beta_t\n",
    "        self.alpha_bar = ... # \\bar\\alpha_t = \\prod_{s=1}^t \\alpha_s computed with torch.cumprod\n",
    "        self.sigma = ... # noise standard deviation at each step : in DDPM, \\sigma_t = \\sqrt{\\beta_t}\n",
    "    \n",
    "    def forward(self, t_idx: Tensor, x_t: Tensor) -> Tensor:\n",
    "        # xt is of shape (batch_size, dim)\n",
    "        # t_idx is of shape (batch_size, 1) : it is the index of the diffusion step, i.e. t in [0, T-1]\n",
    "        \n",
    "        # the NN \\epsilon_\\theta predicts the noise added to the clean position x_0 at time t\n",
    "        # x_t = \\sqrt{\\bar\\alpha_t} x_0 + \\sqrt{1-\\bar\\alpha_t} \\epsilon_\\theta(t, x_t) \n",
    "        \n",
    "        t_emb = (self.t[t_idx]/self.T).view(-1, 1) # simple embedding : normalize t to [0, 1]\n",
    "        input = ... # concatenate x_t and t_emb along dimension 1 using torch.cat\n",
    "        eps = self.net(input)\n",
    "        return eps\n",
    "    \n",
    "    def noising(self, t_idx: Tensor, x_0: Tensor, eps: Tensor = None) -> Tensor: # forward diffusion step\n",
    "        a = ... # use \\bar\\alpha_t at time t=t_idx \n",
    "        if eps is None:\n",
    "            eps = ... # sample standard normal noise of the same shape as x_0\n",
    "        \n",
    "        x_t = ... # compute x_t using the closed form equation of the forward diffusion process (blue box above)\n",
    "        return x_t\n",
    "    \n",
    "    def denoising(self, t_idx: int, x_t: Tensor, method : str = \"DDPM\") -> Tensor:\n",
    "        # Note: t_idx is here the same single integer for the whole batch !\n",
    "        t_idx = Tensor([t_idx]).repeat(x_t.shape[0], 1).long()  # ensure t_idx is a tensor of the right shape\n",
    "        eps = ... # predicted noise to remove at time t_idx from x_t using self.forward\n",
    "        \n",
    "        if method.lower() == \"ddpm\": # stochastic denoising using magenta box equation\n",
    "            \n",
    "            hat_xt = ...\n",
    "            \n",
    "            return hat_xt\n",
    "        \n",
    "        elif method.lower() == \"ddim\" : # deterministic denoising\n",
    "            \n",
    "            hat_xt = ...\n",
    "            \n",
    "            return hat_xt\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(\"Unknown method: choose 'DDPM' or 'DDIM'\")\n",
    "\n",
    "    \n",
    "    def DDIM_denoising(self, t_start: int, t_end: int, x_t: Tensor) -> Tensor:\n",
    "        assert t_start > t_end, \"t_end must be lower than t_start for backward DDIM denoising\"\n",
    "        t_start = Tensor([t_start]).repeat(x_t.shape[0], 1).long() \n",
    "        t_end   = Tensor([t_end  ]).repeat(x_t.shape[0], 1).long()\n",
    "        \n",
    "        eps = self.forward(t_idx=t_start, x_t=x_t)\n",
    "        \n",
    "        hat_xt = ...\n",
    "        \n",
    "        return hat_xt\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DDPM model\n",
    "torch.manual_seed(42)  # For reproducibility\n",
    "ddpm = ... # Initialize DDPM with appropriate parameters\n",
    "\n",
    "# Generate synthetic data\n",
    "n = 1_000\n",
    "data_model = 'radial_gmm'  # Choose from 'moons', 'circles', '2gmm', 'radial_gmm'\n",
    "X0 = ... # sample data using sample_data function\n",
    "\n",
    "print(\"Forward diffusion steps (noising)\")\n",
    "n_steps = 10\n",
    "fig, axes = plt.subplots(1, n_steps + 2, figsize=(30, 4), sharex=True, sharey=True)\n",
    "t_idx = torch.linspace(0,ddpm.T-1,n_steps).long()\n",
    "\n",
    "axes[0].scatter(X0.detach()[:, 0], X0.detach()[:, 1], s=10, color='red')\n",
    "axes[0].set_title(f't = 0 (clean data)')\n",
    "axes[0].set_xlim(-3.0, 3.0)\n",
    "axes[0].set_ylim(-3.0, 3.0)\n",
    "\n",
    "Xt = torch.randn_like(X0)  # prior\n",
    "axes[n_steps+1].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10, color='green')\n",
    "axes[n_steps+1].set_title(f't = \\infty (gaussian prior)')\n",
    "axes[n_steps+1].set_xlim(-3.0, 3.0)\n",
    "axes[n_steps+1].set_ylim(-3.0, 3.0)\n",
    "    \n",
    "for i in range(n_steps):\n",
    "    Xt = ddpm.noising(t_idx=t_idx[i].repeat(X0.shape[0], 1), x_0=X0, eps=None)\n",
    "    axes[i + 1].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10)\n",
    "    axes[i + 1].set_title(f't = {t_idx[i]+1}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Backward diffusion steps (denoising with *untrained* DDPM model)\")\n",
    "n_steps = ddpm.T\n",
    "n_show = 10\n",
    "idx_show = list(torch.linspace(0,ddpm.T-1,n_show).numpy().astype(int))  # time indices to show\n",
    "fig, axes = plt.subplots(1, n_show + 2, figsize=(30, 4), sharex=True, sharey=True)\n",
    "t_idx = torch.linspace(0,ddpm.T-1,n_steps).long()\n",
    "\n",
    "axes[n_show+1].scatter(X0.detach()[:, 0], X0.detach()[:, 1], s=10, color='red')\n",
    "axes[n_show+1].set_title(f'GT')\n",
    "axes[n_show+1].set_xlim(-3.0, 3.0)\n",
    "axes[n_show+1].set_ylim(-3.0, 3.0)\n",
    "    \n",
    "Xt = torch.randn_like(X0)  # start from a random gaussian noise\n",
    "axes[0].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10, color='green')\n",
    "axes[0].set_title(f'time t = {ddpm.T}')\n",
    "\n",
    "%matplotlib inline\n",
    "for i in range(n_steps-1,-1,-1): # reverse order from T to 0\n",
    "    Xt = ddpm.denoising(t_idx=i, x_t=Xt)  # use the trained model to denoise\n",
    "    if t_idx[i] in idx_show:\n",
    "        j = n_show - idx_show.index(t_idx[i])\n",
    "        axes[j].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10)\n",
    "        axes[j].set_title(f't = {t_idx[i]}')\n",
    "        plt.draw()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice 2 : Training and Inference with DDPM and DDIM\n",
    "\n",
    "Complete the following cells to implement the training loop of the DDPM model on the 2D dataset chosen.\n",
    "\n",
    "Recall that the optimisation problem (see the green box above) consists in minimizing the mean squared error between the predicted noise $\\varepsilon_\\theta (x_t, t)$ and the actual noise $\\varepsilon$ added during the forward diffusion process to obtain $x_t$ from $x_0$.\n",
    "The training impose to sample randomly \n",
    "- a batch of clean data points $x_0$ from the training dataset,\n",
    "- a batch of noise vectors $\\varepsilon$ from a standard normal distribution,\n",
    "- a time step $t$ and the corresponding noisy samples $x_t$ from the forward diffusion process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddpm = ... # reinitialize the model\n",
    "\n",
    "optimizer = ... # use your favorite optimizer !\n",
    "criterion = ... # see the green box equation\n",
    "\n",
    "n_iter = 100\n",
    "batch_size = 256\n",
    "\n",
    "losses = []\n",
    "\n",
    "pbar = tqdm(range(n_iter), desc=\"Training Denoising Network (DDPM)\", unit=\"it\")\n",
    "        \n",
    "for it in pbar :\n",
    "    x_0 = ... # sample a batch of size batch_size from X0\n",
    "    # randomly sample a point x_t for t in [1, T]\n",
    "    t_idx = torch.randint(0, ddpm.T, (len(x_0), 1))  # t in [0, T-1]\n",
    "    eps = torch.randn_like(x_0)  # random noise \n",
    "    x_t = ...  # apply the noising step\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss = criterion(ddpm(t_idx=t_idx, x_t=x_t), eps)\n",
    "    loss.backward() # ||\\epsilon_\\theta(t, x_t) - \\varepsilon||^2\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    pbar.set_postfix({'loss'  : f\"{losses[-1]:.4f}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.semilogy(losses, label='loss')\n",
    "ax.set_xlabel('Iteration')\n",
    "fig.suptitle('Training Loss')\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"DDPM\", \"DDIM\"]  # comparison between \"DDPM\" and \"DDIM\"\n",
    "for method in methods:\n",
    "    n_steps = ddpm.T\n",
    "    n_show = 10\n",
    "    idx_show = list(torch.linspace(0,ddpm.T-1,n_show).numpy().astype(int))  # time indices to show\n",
    "    fig, axes = plt.subplots(1, n_show + 2, figsize=(30, 4), sharex=True, sharey=True)\n",
    "    t_idx = torch.linspace(0,ddpm.T-1,n_steps).long()\n",
    "\n",
    "    axes[n_show+1].scatter(X0.detach()[:, 0], X0.detach()[:, 1], s=10, color='red')\n",
    "    axes[n_show+1].set_title(f'GT')\n",
    "    axes[n_show+1].set_xlim(-3.0, 3.0)\n",
    "    axes[n_show+1].set_ylim(-3.0, 3.0)\n",
    "    \n",
    "    torch.manual_seed(42)  # for reproducibility\n",
    "    Xt = torch.randn_like(X0)  # start from a random gaussian noise\n",
    "    axes[0].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10, color='green')\n",
    "    axes[0].set_title(f'time t = {ddpm.T}')\n",
    "    \n",
    "    print(f\"Backward diffusion steps (denoising with _trained_ {method} model) using {n_steps} steps, showing only {n_show}\")\n",
    "    for i in range(n_steps-1,-1,-1): # reverse order from T to 0\n",
    "        Xt = ddpm.denoising(t_idx=i, x_t=Xt, method=method)  # use the trained model to denoise\n",
    "        if t_idx[i] in idx_show:\n",
    "            j = n_show - idx_show.index(t_idx[i])\n",
    "            axes[j].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10)\n",
    "            axes[j].set_title(f't = {t_idx[i]}')\n",
    "            \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Bonus) Exercice 3: accelerated sampling using ODE solvers (DDIM)\n",
    "\n",
    "While the denoising diffusion process can be seen as a discretization of a *stochastic differential equation (SDE)* (at each step some random noise is added),\n",
    "the DDIM denoising process can be interpreted as a discretization of an **ordinary differential equation (ODE)**: from $t=T$ to $t=1$, solving\n",
    "$$\n",
    "    \\frac{dx_t}{dt} = - f(x_t, t)\n",
    "$$\n",
    "where $f(x_t, t)$ is a function that depends on the current state $x_t$ and time $t$, here:\n",
    "$$\n",
    "    f(x_t, t) - x_t = \\sqrt{\\bar \\alpha_t} {\\color{red} \\hat x_0(x_t,t)} +  \\sqrt{1 - \\bar \\alpha_t}\n",
    "\\varepsilon_\\theta (x_t,t)\n",
    "$$\n",
    "\n",
    "Different solvers can be used to solve this ODE, for instance:\n",
    "- *Euler's method:* (already implemented in DDIM above), it consists in approximately solving \n",
    "$$\n",
    "    \\frac{dx_t}{dt} \\approx \\frac{x_t - x_{t-1}}{t - (t-1)} \\Rightarrow x_{t-1} = x_t + f(x_t, t) \n",
    "$$ \n",
    "With large steps $\\Delta t$ (>1 in our setting), we get :\n",
    "$$\n",
    "    x_{t-\\Delta t} = x_t + f(x_t, t) \\Delta t\n",
    "$$\n",
    "\n",
    "- *Heun's method:* improves upon Euler's method by taking an additional step to estimate the slope at the next time point, and then averaging the slopes to update the solution:\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "    k_1 &= f(x_t, t) \\\\\n",
    "    k_2 &= f(x_t + k_1 \\Delta t, t + \\  \\Delta t) \\\\\n",
    "    x_{t-1} &= x_t + \\frac{1}{2}(k_1 + k_2) \\Delta t\n",
    "    \\end{aligned}\n",
    "$$\n",
    "- *Runge-Kutta methods:* more advanced techniques that use multiple intermediate steps to achieve higher accuracy. The most common is the fourth-order Runge-Kutta method (RK4), which computes four slopes at each step and combines them to update the solution:\n",
    "$$\n",
    "    x_{t-1} = x_t + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4) \\Delta t\n",
    "$$\n",
    "where \n",
    "$$ \\begin{aligned}\n",
    "    k_1 &= f(x_t, t) \\\\\n",
    "    k_2 &= f(x_t + \\frac{1}{2} k_1 \\Delta t, t + \\frac{1}{2} \\Delta t) \\\\\n",
    "    k_3 &= f(x_t + \\frac{1}{2} k_2 \\Delta t, t + \\frac{1}{2} \\Delta t) \\\\\n",
    "    k_4 &= f(x_t + k_3 \\Delta t, t + \\Delta t)\n",
    "\\end{aligned} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration with DDIM using large steps\n",
    "n_steps = 20\n",
    "n_show = 10\n",
    "fig, axes = plt.subplots(1, n_show + 2, figsize=(30, 4), sharex=True, sharey=True)\n",
    "\n",
    "tau_idx   = torch.linspace(0,ddpm.T-1,n_steps).long() # only n_steps time steps are used now !\n",
    "\n",
    "axes[n_show+1].scatter(X0.detach()[:, 0], X0.detach()[:, 1], s=10, color='red')\n",
    "axes[n_show+1].set_title(f'GT')\n",
    "axes[n_show+1].set_xlim(-3.0, 3.0)\n",
    "axes[n_show+1].set_ylim(-3.0, 3.0)\n",
    "\n",
    "torch.manual_seed(42)  # for reproducibility\n",
    "Xt = torch.randn_like(X0)  # start from a random gaussian noise\n",
    "axes[0].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10, color='green')\n",
    "axes[0].set_title(f'time t = {ddpm.T}')\n",
    "\n",
    "print(f\"Accelerated Backward diffusion steps with DDIM using {n_steps} steps, showing only {n_show}\")\n",
    "j = 0\n",
    "for i in range(n_steps-1,0,-1): # reverse order from T to 0\n",
    "    #print(f\"Step {i}:{tau_idx[i]} / {n_steps-1} -> {i-1}:{tau_idx[i-1]}\")\n",
    "    Xt = ddpm.DDIM_denoising(t_start=tau_idx[i], t_end=tau_idx[i-1], x_t=Xt)\n",
    "    if (ddpm.T - tau_idx[i]) > (j * ddpm.T) // (n_show-1):\n",
    "        j += 1\n",
    "        #print(f\"Showing t = {tau_idx[i-1]} @ {j=}\")\n",
    "        axes[j].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10)\n",
    "        axes[j].set_title(f't = {tau_idx[i-1]}')\n",
    "# last step : predict the final denoised position at t=0\n",
    "Xt = ddpm.DDIM_denoising(t_start=tau_idx[1], t_end=0, x_t=Xt)  \n",
    "j = n_show\n",
    "axes[j].scatter(Xt.detach()[:, 0], Xt.detach()[:, 1], s=10)\n",
    "axes[j].set_title(f't = {tau_idx[0]}')  \n",
    "    \n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_demo_deep_gen_model",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
